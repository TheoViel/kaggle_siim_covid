{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/kaggle/siim_covid/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_dataframe, handle_duplicates\n",
    "from data.dataset import CovidDetDataset, CovidClsDataset\n",
    "from data.transforms import get_transfos_det, get_transfos_cls\n",
    "\n",
    "from model_zoo.models import get_model\n",
    "\n",
    "from utils.plot import plot_sample\n",
    "\n",
    "from utils.logger import Config\n",
    "\n",
    "from utils.metrics import per_class_average_precision_score, study_level_map, study_level_map_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-07-30/4/\",\n",
    "#     LOG_PATH + \"2021-07-31/0/\",\n",
    "#     LOG_PATH + \"2021-08-01/0/\",\n",
    "#     LOG_PATH + \"2021-08-01/1/\",\n",
    "]\n",
    "\n",
    "EXP_FOLDER = EXP_FOLDERS[-1]\n",
    "\n",
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TTA:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "else:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study.npy\") for f in EXP_FOLDERS], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(EXP_FOLDER + \"data.csv\")\n",
    "\n",
    "pred_cols = [c + \"_pred\" for c in CLASSES]\n",
    "df[pred_cols] = pred_oof_study\n",
    "df['pred_img'] = pred_oof_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['kfold'] == 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9632\n",
      "Image AUC : 0.9173\n",
      "Image Acc : 0.8491\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(df['pred_img'].values, df['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "\n",
    "auc = roc_auc_score(df['img_target'], df['pred_img'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(df['img_target'], df['pred_img'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32469325308563324"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_level_map_binary(df['indeterminate_pred'], df['study_label'] == 'indeterminate', df['study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.3784\n"
     ]
    }
   ],
   "source": [
    "study_map = study_level_map(df[pred_cols].values, df[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Img merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df[['study_id', 'pred_img']].groupby('study_id').mean().rename(\n",
    "    columns={'pred_img': 'pred_img_merged'}\n",
    ").reset_index()\n",
    "df_ = df.merge(groups, on=\"study_id\", how=\"left\")\n",
    "\n",
    "# df_.loc[df_['negative_pred'] > 0.75, 'pred_img'] = 0\n",
    "# df_.loc[df_['typical_pred'] > 0.75, 'pred_img'] = 1\n",
    "# df_.loc[df_['indeterminate_pred'] > 0.75, 'pred_img'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9605\n",
      "Image AUC : 0.9110\n",
      "Image Acc : 0.8470\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(df_['pred_img_merged'].values, df['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(df_['img_target'], df_['pred_img_merged'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(df_['img_target'], df_['pred_img_merged'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study using img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.38327\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy()\n",
    "\n",
    "p = 0.5\n",
    "df_['negative_pred'] *= (1 - df_['pred_img']) ** p\n",
    "df_['typical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "# df_['indeterminate_pred'] *= (df_['pred_img']) ** p\n",
    "# df_['atypical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "study_map = study_level_map(df_[pred_cols].values, df_[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.802 , 0.8478, 0.3069, 0.3421]), 0.3831)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = df[\n",
    "    ['study_id'] + pred_cols + CLASSES + ['img_target', 'pred_img']\n",
    "].groupby('study_id').agg(np.mean).copy()\n",
    "\n",
    "# df_study['negative_pred'] *= 1 - df_study['pred_img'] \n",
    "# df_study['typical_pred'] *= df_study['pred_img'] \n",
    "# df_study['indeterminate_pred'] *= df_study['pred_img'] \n",
    "# df_study['atypical_pred'] *= df_study['pred_img'] \n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'negative_pred'] *= 0.5\n",
    "df_study.loc[df_study['pred_img'] < 0.2, 'negative_pred'] *= 2\n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'typical_pred'] *= 1.2\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'indeterminate_pred'] *= 1.1\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'atypical_pred'] *= 1.1\n",
    "\n",
    "df_study.loc[df_study['pred_img'] < 0.25, 'typical_pred'] *= 0.8\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'indeterminate_pred'] *= 0.9\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'atypical_pred'] *= 0.9\n",
    "\n",
    "accs = per_class_average_precision_score(\n",
    "    df_study[pred_cols].values,\n",
    "    df_study[CLASSES].values, \n",
    "    num_classes=NUM_CLASSES, \n",
    "    average=False\n",
    ")\n",
    "np.round(accs, 4), np.round(np.mean(accs) * 2/3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(x):\n",
    "    x = x.split('0 0 1 1')[:4]\n",
    "    x = [float(y.strip().split(' ')[1]) for y in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "sub_study = sub[sub['id'].apply(lambda x: \"study\" in x)].copy()\n",
    "\n",
    "pred_test = np.array(sub_study['PredictionString'].apply(proc).values.tolist())\n",
    "\n",
    "for i, c in enumerate(CLASSES):\n",
    "    sub_study[c] = pred_test[:, i]\n",
    "    \n",
    "sub_study.to_csv(\"../output/sub_0931_study.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "\n",
    "sub_img = sub[sub['id'].apply(lambda x: \"study\" not in x)].copy()\n",
    "sub_img['none'] = sub_img['PredictionString'].apply(lambda x: float(x.split('none')[-1].strip().split(' ')[0]))\n",
    "\n",
    "sub_img.to_csv(\"../output/sub_0931_img.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_oof(pred_oof_study):\n",
    "    pred_oof_study['id'] = pred_oof_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    \n",
    "    df_study = pd.read_csv(DATA_PATH + \"train_study_level.csv\")\n",
    "    df_study['study_id'] = df_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    df_study = df_study.rename(columns={c: c.split(' ')[0].lower() for c in df_study.columns})\n",
    "\n",
    "    df_study.drop('id', axis=1, inplace=True)\n",
    "\n",
    "    df_study = df_study.merge(pred_oof_study, how=\"left\", left_on=\"study_id\", right_on=\"id\").dropna()\n",
    "    \n",
    "    pred_oof_study = np.array(df_study['PredictionString'].apply(proc).values.tolist())\n",
    "    \n",
    "    df_study[pred_cols] = pred_oof_study\n",
    "    \n",
    "    df_g = df[['study_id'] + pred_cols].groupby('study_id').mean().reset_index()\n",
    "    df_study = df_study.merge(df_g, how=\"left\", left_on=\"id\", right_on=\"study_id\", suffixes=['', '_theo'])\n",
    "    \n",
    "    return df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = treat_oof(pd.read_csv('../output/OOF_study_only_EBV2M_768.csv'))\n",
    "df_v2m_2 = treat_oof(pd.read_csv('../output/oof_v2m.csv'))\n",
    "df_b4 = treat_oof(pd.read_csv('../output/oof_b4.csv'))\n",
    "df_b5 = treat_oof(pd.read_csv('../output/oof_b5.csv'))\n",
    "df_ono = treat_oof(pd.read_csv('../output/oof_ono.csv')[['id', 'PredictionString']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theo = df[['study_id'] + pred_cols + CLASSES].groupby('study_id').mean().reset_index()\n",
    "df_theo = df_v2m_2[['id']].merge(df_theo, how=\"left\", left_on=\"id\", right_on=\"study_id\")\n",
    "\n",
    "df_ono = df_v2m_2[['id']].merge(df_ono, how=\"left\", left_on=\"id\", right_on=\"study_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "oofs = [\n",
    "#     df_old[pred_cols].values ** p * 1,\n",
    "    df_theo[pred_cols].values ** p * 1,\n",
    "    df_v2m_2[pred_cols].values ** p * 1,\n",
    "#     df_b4[pred_cols].values ** p * 0.1,\n",
    "    df_b5[pred_cols].values ** p * 0.5,\n",
    "#     df_ono[pred_cols].values ** p * 0.1,\n",
    "]\n",
    "\n",
    "oof = np.mean(oofs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81562984, 0.81986495, 0.45891351, 0.71444997])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'typical', 'indeterminate', 'atypical']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth = df_theo[CLASSES].values\n",
    "# pred = oof\n",
    "# aucs = [roc_auc_score(truth[:, i].flatten(), pred[:, i].flatten()) for i in range(pred.shape[1])]\n",
    "# aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4):\n",
    "#     print(pearsonr(pred[:, 2], pred[:, i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39189165578531077"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES) * 2 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81115651, 0.85174298, 0.3206541 , 0.36779635])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES, average=False) #* 2 / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk = pd.read_csv(\"../output/oof_image_level_mk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8851199771832216"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(oof_mk['target'], oof_mk['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk = oof_mk.merge(df, on='image_id', how='left')[['image_id', 'img_target', 'pred_img', 'pred']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9528\n",
      "Image AUC : 0.8916\n",
      "Image Acc : 0.8339\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(oof_mk['pred'].values, oof_mk['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(oof_mk['img_target'], oof_mk['pred'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(oof_mk['pred'] > 0.5, oof_mk['img_target'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9604\n",
      "Image AUC : 0.9109\n",
      "Image Acc : 0.8460\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(oof_mk['pred_img'].values, oof_mk['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(oof_mk['img_target'], oof_mk['pred_img'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(oof_mk['pred_img'] > 0.5, oof_mk['img_target'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk['blend'] = (oof_mk['pred_img'] * 4 + oof_mk['pred']) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9615\n",
      "Image AUC : 0.9123\n",
      "Image Acc : 0.8487\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(oof_mk['blend'].values, oof_mk['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(oof_mk['img_target'], oof_mk['blend'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(oof_mk['blend'] > 0.5, oof_mk['img_target'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
