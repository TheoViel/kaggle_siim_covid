{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/kaggle/siim_covid/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_dataframe, handle_duplicates\n",
    "from data.dataset import CovidDetDataset, CovidClsDataset\n",
    "from data.transforms import get_transfos_det, get_transfos_cls\n",
    "\n",
    "from model_zoo.models import get_model\n",
    "\n",
    "from utils.plot import plot_sample\n",
    "\n",
    "from utils.logger import Config\n",
    "\n",
    "from utils.metrics import per_class_average_precision_score, study_level_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-07-30/4/\",\n",
    "    LOG_PATH + \"2021-07-31/0/\",\n",
    "#     LOG_PATH + \"2021-08-01/0/\",\n",
    "    LOG_PATH + \"2021-08-01/1/\",\n",
    "]\n",
    "\n",
    "EXP_FOLDER = EXP_FOLDERS[-1]\n",
    "\n",
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TTA:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "else:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study.npy\") for f in EXP_FOLDERS], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(EXP_FOLDER + \"data.csv\")\n",
    "\n",
    "pred_cols = [c + \"_pred\" for c in CLASSES]\n",
    "df[pred_cols] = pred_oof_study\n",
    "df['pred_img'] = pred_oof_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.962\n",
      "Image AUC : 0.912\n",
      "Image Acc : 0.846\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(pred_oof_img, df['img_target'].values)\n",
    "print(f'Image mAP : {ap :.3f}')\n",
    "\n",
    "auc = roc_auc_score(df['img_target'], pred_oof_img)\n",
    "print(f'Image AUC : {auc :.3f}')\n",
    "acc = accuracy_score(df['img_target'], pred_oof_img > 0.5)\n",
    "print(f'Image Acc : {acc :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.3837\n"
     ]
    }
   ],
   "source": [
    "study_map = study_level_map(df[pred_cols].values, df[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Img merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df[['study_id', 'pred_img']].groupby('study_id').mean().rename(\n",
    "    columns={'pred_img': 'pred_img_merged'}\n",
    ").reset_index()\n",
    "df_ = df.merge(groups, on=\"study_id\", how=\"left\")\n",
    "\n",
    "df_.loc[df_['negative_pred'] > 0.75, 'pred_img'] = 0\n",
    "df_.loc[df_['typical_pred'] > 0.75, 'pred_img'] = 1\n",
    "df_.loc[df_['indeterminate_pred'] > 0.75, 'pred_img'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image AUC : 0.905\n",
      "Image Acc : 0.8465\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(df_['img_target'], df_['pred_img'])\n",
    "print(f'Image AUC : {auc :.3f}')\n",
    "acc = accuracy_score(df_['img_target'], df_['pred_img'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study using img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.38327\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy()\n",
    "\n",
    "p = 0.5\n",
    "df_['negative_pred'] *= (1 - df_['pred_img']) ** p\n",
    "df_['typical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "# df_['indeterminate_pred'] *= (df_['pred_img']) ** p\n",
    "# df_['atypical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "study_map = study_level_map(df_[pred_cols].values, df_[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.802 , 0.8478, 0.3069, 0.3421]), 0.3831)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = df[\n",
    "    ['study_id'] + pred_cols + CLASSES + ['img_target', 'pred_img']\n",
    "].groupby('study_id').agg(np.mean).copy()\n",
    "\n",
    "# df_study['negative_pred'] *= 1 - df_study['pred_img'] \n",
    "# df_study['typical_pred'] *= df_study['pred_img'] \n",
    "# df_study['indeterminate_pred'] *= df_study['pred_img'] \n",
    "# df_study['atypical_pred'] *= df_study['pred_img'] \n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'negative_pred'] *= 0.5\n",
    "df_study.loc[df_study['pred_img'] < 0.2, 'negative_pred'] *= 2\n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'typical_pred'] *= 1.2\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'indeterminate_pred'] *= 1.1\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'atypical_pred'] *= 1.1\n",
    "\n",
    "df_study.loc[df_study['pred_img'] < 0.25, 'typical_pred'] *= 0.8\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'indeterminate_pred'] *= 0.9\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'atypical_pred'] *= 0.9\n",
    "\n",
    "accs = per_class_average_precision_score(\n",
    "    df_study[pred_cols].values,\n",
    "    df_study[CLASSES].values, \n",
    "    num_classes=NUM_CLASSES, \n",
    "    average=False\n",
    ")\n",
    "np.round(accs, 4), np.round(np.mean(accs) * 2/3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(x):\n",
    "    x = x.split('0 0 1 1')[:4]\n",
    "    x = [float(y.strip().split(' ')[1]) for y in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>negative</th>\n",
       "      <th>typical</th>\n",
       "      <th>indeterminate</th>\n",
       "      <th>atypical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00188a671292_study</td>\n",
       "      <td>negative 0.8009114503860474 0 0 1 1 typical 0....</td>\n",
       "      <td>0.800911</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.054812</td>\n",
       "      <td>0.016894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004bd59708be_study</td>\n",
       "      <td>negative 0.0055577514367178 0 0 1 1 typical 0....</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.808095</td>\n",
       "      <td>0.073134</td>\n",
       "      <td>0.013214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00508faccd39_study</td>\n",
       "      <td>negative 0.5854789519309997 0 0 1 1 typical 0....</td>\n",
       "      <td>0.585479</td>\n",
       "      <td>0.096047</td>\n",
       "      <td>0.140624</td>\n",
       "      <td>0.077850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006486aa80b2_study</td>\n",
       "      <td>negative 0.2664635345339775 0 0 1 1 typical 0....</td>\n",
       "      <td>0.266464</td>\n",
       "      <td>0.246429</td>\n",
       "      <td>0.310248</td>\n",
       "      <td>0.076859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00655178fdfc_study</td>\n",
       "      <td>negative 0.5432932925224304 0 0 1 1 typical 0....</td>\n",
       "      <td>0.543293</td>\n",
       "      <td>0.150926</td>\n",
       "      <td>0.170696</td>\n",
       "      <td>0.035084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>ff1ba0e9aaf0_study</td>\n",
       "      <td>negative 0.2834496781229972 0 0 1 1 typical 0....</td>\n",
       "      <td>0.283450</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.217058</td>\n",
       "      <td>0.045693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>ff2cc4de58c5_study</td>\n",
       "      <td>negative 0.0885573822632432 0 0 1 1 typical 0....</td>\n",
       "      <td>0.088557</td>\n",
       "      <td>0.138054</td>\n",
       "      <td>0.389064</td>\n",
       "      <td>0.284325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>ff2f0a744930_study</td>\n",
       "      <td>negative 0.0028401464549824 0 0 1 1 typical 0....</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.839094</td>\n",
       "      <td>0.047694</td>\n",
       "      <td>0.010372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>ff88940dce8b_study</td>\n",
       "      <td>negative 0.5658159017562866 0 0 1 1 typical 0....</td>\n",
       "      <td>0.565816</td>\n",
       "      <td>0.157659</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>0.035423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>fff7ef24961f_study</td>\n",
       "      <td>negative 0.1235070532560348 0 0 1 1 typical 0....</td>\n",
       "      <td>0.123507</td>\n",
       "      <td>0.614555</td>\n",
       "      <td>0.140786</td>\n",
       "      <td>0.021152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1214 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                   PredictionString  \\\n",
       "0     00188a671292_study  negative 0.8009114503860474 0 0 1 1 typical 0....   \n",
       "1     004bd59708be_study  negative 0.0055577514367178 0 0 1 1 typical 0....   \n",
       "2     00508faccd39_study  negative 0.5854789519309997 0 0 1 1 typical 0....   \n",
       "3     006486aa80b2_study  negative 0.2664635345339775 0 0 1 1 typical 0....   \n",
       "4     00655178fdfc_study  negative 0.5432932925224304 0 0 1 1 typical 0....   \n",
       "...                  ...                                                ...   \n",
       "1209  ff1ba0e9aaf0_study  negative 0.2834496781229972 0 0 1 1 typical 0....   \n",
       "1210  ff2cc4de58c5_study  negative 0.0885573822632432 0 0 1 1 typical 0....   \n",
       "1211  ff2f0a744930_study  negative 0.0028401464549824 0 0 1 1 typical 0....   \n",
       "1212  ff88940dce8b_study  negative 0.5658159017562866 0 0 1 1 typical 0....   \n",
       "1213  fff7ef24961f_study  negative 0.1235070532560348 0 0 1 1 typical 0....   \n",
       "\n",
       "      negative   typical  indeterminate  atypical  \n",
       "0     0.800911  0.027383       0.054812  0.016894  \n",
       "1     0.005558  0.808095       0.073134  0.013214  \n",
       "2     0.585479  0.096047       0.140624  0.077850  \n",
       "3     0.266464  0.246429       0.310248  0.076859  \n",
       "4     0.543293  0.150926       0.170696  0.035084  \n",
       "...        ...       ...            ...       ...  \n",
       "1209  0.283450  0.353800       0.217058  0.045693  \n",
       "1210  0.088557  0.138054       0.389064  0.284325  \n",
       "1211  0.002840  0.839094       0.047694  0.010372  \n",
       "1212  0.565816  0.157659       0.141102  0.035423  \n",
       "1213  0.123507  0.614555       0.140786  0.021152  \n",
       "\n",
       "[1214 rows x 6 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "sub_study = sub[sub['id'].apply(lambda x: \"study\" in x)].copy()\n",
    "\n",
    "pred_test = np.array(sub_study['PredictionString'].apply(proc).values.tolist())\n",
    "\n",
    "for i, c in enumerate(CLASSES):\n",
    "    sub_study[c] = pred_test[:, i]\n",
    "    \n",
    "sub_study.to_csv(\"../output/sub_0931_study.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "\n",
    "sub_img = sub[sub['id'].apply(lambda x: \"study\" not in x)].copy()\n",
    "sub_img['none'] = sub_img['PredictionString'].apply(lambda x: float(x.split('none')[-1].strip().split(' ')[0]))\n",
    "\n",
    "sub_img.to_csv(\"../output/sub_0931_img.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_oof(pred_oof_study):\n",
    "    pred_oof_study['id'] = pred_oof_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    \n",
    "    df_study = pd.read_csv(DATA_PATH + \"train_study_level.csv\")\n",
    "    df_study['study_id'] = df_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    df_study = df_study.rename(columns={c: c.split(' ')[0].lower() for c in df_study.columns})\n",
    "\n",
    "    df_study.drop('id', axis=1, inplace=True)\n",
    "\n",
    "    df_study = df_study.merge(pred_oof_study, how=\"left\", left_on=\"study_id\", right_on=\"id\").dropna()\n",
    "    \n",
    "    pred_oof_study = np.array(df_study['PredictionString'].apply(proc).values.tolist())\n",
    "    \n",
    "    df_study[pred_cols] = pred_oof_study\n",
    "    \n",
    "    df_g = df[['study_id'] + pred_cols].groupby('study_id').mean().reset_index()\n",
    "    df_study = df_study.merge(df_g, how=\"left\", left_on=\"id\", right_on=\"study_id\", suffixes=['', '_theo'])\n",
    "    \n",
    "    return df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = treat_oof(pd.read_csv('../output/OOF_study_only_EBV2M_768.csv'))\n",
    "df_v2m_2 = treat_oof(pd.read_csv('../output/oof_v2m.csv'))\n",
    "df_b4 = treat_oof(pd.read_csv('../output/oof_b4.csv'))\n",
    "df_b5 = treat_oof(pd.read_csv('../output/oof_b5.csv'))\n",
    "df_ono = treat_oof(pd.read_csv('../output/oof_ono.csv')[['id', 'PredictionString']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theo = df[['study_id'] + pred_cols + CLASSES].groupby('study_id').mean().reset_index()\n",
    "df_theo = df_v2m_2[['id']].merge(df_theo, how=\"left\", left_on=\"id\", right_on=\"study_id\")\n",
    "\n",
    "df_ono = df_v2m_2[['id']].merge(df_ono, how=\"left\", left_on=\"id\", right_on=\"study_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "oofs = [\n",
    "#     df_old[pred_cols].values ** p * 1,\n",
    "    df_theo[pred_cols].values ** p * 1,\n",
    "    df_v2m_2[pred_cols].values ** p * 1,\n",
    "#     df_b4[pred_cols].values ** p * 0.1,\n",
    "    df_b5[pred_cols].values ** p * 0.5,\n",
    "#     df_ono[pred_cols].values ** p * 0.1,\n",
    "]\n",
    "\n",
    "oof = np.mean(oofs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81562984, 0.81986495, 0.45891351, 0.71444997])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'typical', 'indeterminate', 'atypical']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31101399733824325\n",
      "-0.07768501668761119\n",
      "1.0\n",
      "0.4056669876265603\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(pearsonr(pred[:, 2], pred[:, i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9243023088403703,\n",
       " 0.8713742063953793,\n",
       " 0.6932290198865377,\n",
       " 0.8066562284884381]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = df_theo[CLASSES].values\n",
    "pred = oof\n",
    "aucs = [roc_auc_score(truth[:, i].flatten(), pred[:, i].flatten()) for i in range(pred.shape[1])]\n",
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39189165578531077"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES) * 2 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81115651, 0.85174298, 0.3206541 , 0.36779635])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES, average=False) #* 2 / 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
