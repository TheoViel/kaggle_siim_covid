{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to validate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/theo/kaggle/siim_covid/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_dataframe, handle_duplicates\n",
    "from data.dataset import CovidDetDataset, CovidClsDataset\n",
    "from data.transforms import get_transfos_det, get_transfos_cls\n",
    "\n",
    "from model_zoo.models import get_model\n",
    "\n",
    "from utils.plot import plot_sample\n",
    "\n",
    "from utils.logger import Config\n",
    "\n",
    "from utils.metrics import per_class_average_precision_score, study_level_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    LOG_PATH + \"2021-07-30/4/\",\n",
    "    LOG_PATH + \"2021-07-31/0/\",\n",
    "#     LOG_PATH + \"2021-08-01/0/\",\n",
    "#     LOG_PATH + \"2021-08-01/1/\",\n",
    "#     LOG_PATH +  \"aphrodeep_v2s_lung/\"\n",
    "]\n",
    "\n",
    "EXP_FOLDER = EXP_FOLDERS[-1]\n",
    "\n",
    "USE_TTA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(json.load(open(EXP_FOLDER + \"config.json\", 'r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TTA:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study_flip.npy\") for f in EXP_FOLDERS], 0)\n",
    "else:\n",
    "    pred_oof_img = np.mean([np.load(f + \"pred_oof_img.npy\") for f in EXP_FOLDERS], 0)\n",
    "    pred_oof_study = np.mean([np.load(f + \"pred_oof_study.npy\") for f in EXP_FOLDERS], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(EXP_FOLDER + \"data.csv\")\n",
    "\n",
    "pred_cols = [c + \"_pred\" for c in CLASSES]\n",
    "df[pred_cols] = pred_oof_study\n",
    "df['pred_img'] = pred_oof_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     print(df[df['kfold'] == i][pred_cols].max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9604\n",
      "Image AUC : 0.9108\n",
      "Image Acc : 0.8465\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(pred_oof_img, df['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "\n",
    "auc = roc_auc_score(df['img_target'], pred_oof_img)\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(df['img_target'], pred_oof_img > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.3831\n"
     ]
    }
   ],
   "source": [
    "study_map = study_level_map(df[pred_cols].values, df[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Img merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df[['study_id', 'pred_img']].groupby('study_id').mean().rename(\n",
    "    columns={'pred_img': 'pred_img_merged'}\n",
    ").reset_index()\n",
    "df_ = df.merge(groups, on=\"study_id\", how=\"left\")\n",
    "\n",
    "# df_.loc[df_['negative_pred'] > 0.75, 'pred_img'] = 0\n",
    "# df_.loc[df_['typical_pred'] > 0.75, 'pred_img'] = 1\n",
    "# df_.loc[df_['indeterminate_pred'] > 0.75, 'pred_img'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9605\n",
      "Image AUC : 0.9110\n",
      "Image Acc : 0.8470\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(df_['pred_img_merged'].values, df['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(df_['img_target'], df_['pred_img_merged'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(df_['img_target'], df_['pred_img_merged'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study using img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.38327\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy()\n",
    "\n",
    "p = 0.5\n",
    "df_['negative_pred'] *= (1 - df_['pred_img']) ** p\n",
    "df_['typical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "# df_['indeterminate_pred'] *= (df_['pred_img']) ** p\n",
    "# df_['atypical_pred'] *= (df_['pred_img']) ** p\n",
    "\n",
    "study_map = study_level_map(df_[pred_cols].values, df_[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.802 , 0.8478, 0.3069, 0.3421]), 0.3831)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = df[\n",
    "    ['study_id'] + pred_cols + CLASSES + ['img_target', 'pred_img']\n",
    "].groupby('study_id').agg(np.mean).copy()\n",
    "\n",
    "# df_study['negative_pred'] *= 1 - df_study['pred_img'] \n",
    "# df_study['typical_pred'] *= df_study['pred_img'] \n",
    "# df_study['indeterminate_pred'] *= df_study['pred_img'] \n",
    "# df_study['atypical_pred'] *= df_study['pred_img'] \n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'negative_pred'] *= 0.5\n",
    "df_study.loc[df_study['pred_img'] < 0.2, 'negative_pred'] *= 2\n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'typical_pred'] *= 1.2\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'indeterminate_pred'] *= 1.1\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'atypical_pred'] *= 1.1\n",
    "\n",
    "df_study.loc[df_study['pred_img'] < 0.25, 'typical_pred'] *= 0.8\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'indeterminate_pred'] *= 0.9\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'atypical_pred'] *= 0.9\n",
    "\n",
    "accs = per_class_average_precision_score(\n",
    "    df_study[pred_cols].values,\n",
    "    df_study[CLASSES].values, \n",
    "    num_classes=NUM_CLASSES, \n",
    "    average=False\n",
    ")\n",
    "np.round(accs, 4), np.round(np.mean(accs) * 2/3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(x):\n",
    "    x = x.split('0 0 1 1')[:4]\n",
    "    x = [float(y.strip().split(' ')[1]) for y in x]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "sub_study = sub[sub['id'].apply(lambda x: \"study\" in x)].copy()\n",
    "\n",
    "pred_test = np.array(sub_study['PredictionString'].apply(proc).values.tolist())\n",
    "\n",
    "for i, c in enumerate(CLASSES):\n",
    "    sub_study[c] = pred_test[:, i]\n",
    "    \n",
    "sub_study.to_csv(\"../output/sub_0931_study.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../output/sub_0931.csv\")\n",
    "\n",
    "sub_img = sub[sub['id'].apply(lambda x: \"study\" not in x)].copy()\n",
    "sub_img['none'] = sub_img['PredictionString'].apply(lambda x: float(x.split('none')[-1].strip().split(' ')[0]))\n",
    "\n",
    "sub_img.to_csv(\"../output/sub_0931_img.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_oof(pred_oof_study):\n",
    "    pred_oof_study['id'] = pred_oof_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    \n",
    "    df_study = pd.read_csv(DATA_PATH + \"train_study_level.csv\")\n",
    "    df_study['study_id'] = df_study['id'].apply(lambda x: x.split('_')[0])\n",
    "    df_study = df_study.rename(columns={c: c.split(' ')[0].lower() for c in df_study.columns})\n",
    "\n",
    "    df_study.drop('id', axis=1, inplace=True)\n",
    "\n",
    "    df_study = df_study.merge(pred_oof_study, how=\"left\", left_on=\"study_id\", right_on=\"id\").dropna()\n",
    "    \n",
    "    pred_oof_study = np.array(df_study['PredictionString'].apply(proc).values.tolist())\n",
    "    \n",
    "    df_study[pred_cols] = pred_oof_study\n",
    "    \n",
    "    df_g = df[['study_id'] + pred_cols].groupby('study_id').mean().reset_index()\n",
    "    df_study = df_study.merge(df_g, how=\"left\", left_on=\"id\", right_on=\"study_id\", suffixes=['', '_theo'])\n",
    "    \n",
    "    return df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = treat_oof(pd.read_csv('../output/OOF_study_only_EBV2M_768.csv'))\n",
    "df_v2m_2 = treat_oof(pd.read_csv('../output/oof_v2m.csv'))\n",
    "df_b4 = treat_oof(pd.read_csv('../output/oof_b4.csv'))\n",
    "df_b5 = treat_oof(pd.read_csv('../output/oof_b5.csv'))\n",
    "df_ono = treat_oof(pd.read_csv('../output/oof_ono.csv')[['id', 'PredictionString']])\n",
    "df_v2m_640 = treat_oof(pd.read_csv('../output/submit_OOF_V2M_640.csv'))\n",
    "df_b6 = treat_oof(pd.read_csv('../output/submit_OOF_B6_512.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theo = df[['study_id'] + pred_cols + CLASSES].groupby('study_id').mean().reset_index()\n",
    "df_theo = df_v2m_2[['id']].merge(df_theo, how=\"left\", left_on=\"id\", right_on=\"study_id\")\n",
    "\n",
    "df_ono = df_v2m_2[['id']].merge(df_ono, how=\"left\", left_on=\"id\", right_on=\"study_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 1\n",
    "\n",
    "oofs = [\n",
    "#     df_old[pred_cols].values ** p * 1,\n",
    "    df_theo[pred_cols].values ** p * 1,\n",
    "    df_v2m_2[pred_cols].values ** p * 1,\n",
    "#     df_b4[pred_cols].values ** p * 0.1,\n",
    "    df_b5[pred_cols].values ** p * 0.5,\n",
    "#     df_ono[pred_cols].values ** p * 0.5,\n",
    "    df_b6[pred_cols].values ** p * 0.5,\n",
    "#     df_v2m_640[pred_cols].values ** p * 1,\n",
    "]\n",
    "\n",
    "oof = np.mean(oofs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9243240146654443,\n",
       " 0.8716498208065167,\n",
       " 0.6946356202443238,\n",
       " 0.8080906189641159]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = df_theo[CLASSES].values\n",
    "pred = oof\n",
    "aucs = [roc_auc_score(truth[:, i].flatten(), pred[:, i].flatten()) for i in range(pred.shape[1])]\n",
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39228991794419105"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES) * 2 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81232886, 0.85242912, 0.32088746, 0.36809407])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof, df_theo[CLASSES].values, num_classes=NUM_CLASSES, average=False) #* 2 / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blend img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk = pd.read_csv(\"../output/oof_image_level_tf_efficientnet_b4_ns.csv\")\n",
    "oof_mk = oof_mk.merge(df, on='image_id', how='left')[['image_id', 'img_target', 'pred_img', 'pred']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk_2 = pd.read_csv(\"../output/oof_image_level_tf_efficientnet_b3_ns.csv\")\n",
    "oof_mk_2 = oof_mk_2.merge(df, on='image_id', how='left')[['image_id', 'img_target', 'pred_img', 'pred']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk_3 = pd.read_csv(\"../output/oof_image_level_tf_efficientnet_b5_ns.csv\")\n",
    "oof_mk_3 = oof_mk_3.merge(df, on='image_id', how='left')[['image_id', 'img_target', 'pred_img', 'pred']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9531\n",
      "Image AUC : 0.8940\n"
     ]
    }
   ],
   "source": [
    "file = oof_mk_2\n",
    "ap = per_class_average_precision_score(file['pred'].values, file['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(file['img_target'], file['pred'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "# acc = accuracy_score(file['pred'] > 0.5, file['img_target'] > 0.5)\n",
    "# print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9604\n",
      "Image AUC : 0.9109\n",
      "Image Acc : 0.8460\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(oof_mk['pred_img'].values, oof_mk['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(oof_mk['img_target'], oof_mk['pred_img'])\n",
    "print(f'Image AUC : {auc :.4f}')\n",
    "acc = accuracy_score(oof_mk['pred_img'] > 0.5, oof_mk['img_target'] > 0.5)\n",
    "print(f'Image Acc : {acc :.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = 1\n",
    "oof_mk['blend'] = oof_mk['pred_img'] ** P * 3 + oof_mk_2['pred'] ** P * 0.5 + oof_mk_3['pred'] ** P * 1 + oof_mk['pred'] ** P * 0\n",
    "oof_mk['blend']  = oof_mk['blend'] / oof_mk['blend'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image mAP : 0.9626\n",
      "Image AUC : 0.9127\n"
     ]
    }
   ],
   "source": [
    "ap = per_class_average_precision_score(oof_mk['blend'].values, oof_mk['img_target'].values)\n",
    "print(f'Image mAP : {ap :.4f}')\n",
    "auc = roc_auc_score(oof_mk['img_target'], oof_mk['blend'])\n",
    "print(f'Image AUC : {auc :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk[\"blend_mk\"] = (oof_mk_2['pred'] + oof_mk_3['pred'] + oof_mk['pred']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk = oof_mk.merge(df[['study_id', 'image_id']] , how=\"left\", on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk = oof_mk.merge(df_theo, how=\"left\", on=\"study_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof_mk = oof_mk.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_mk.to_csv('../output/final_blend.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38319520568661075"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_level_map(oof_mk[pred_cols].values, oof_mk[CLASSES].values, oof_mk['study_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624656477013465"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_average_precision_score(oof_mk['blend'].values, oof_mk['img_target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oof_mk.copy()\n",
    "df['pred_img'] = df['blend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study mAP : 0.38391\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy()\n",
    "\n",
    "p = 1\n",
    "df_['negative_pred'] *= (1 - df_['blend_mk']) ** p\n",
    "df_['typical_pred'] *= (df_['blend']) ** p\n",
    "\n",
    "# df_['negative_pred'] -= df_['blend_mk'] ** p\n",
    "# df_['typical_pred'] += df_['blend'] ** p\n",
    "\n",
    "# df_['indeterminate_pred'] *= (df_['pred_img']) ** p\n",
    "# df_['atypical_pred'] += (df_['blend_mk']) ** p\n",
    "\n",
    "study_map = study_level_map(df_[pred_cols].values, df_[CLASSES].values, df['study_id'].values)\n",
    "print(f'Study mAP : {study_map :.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8023, 0.8477, 0.3076, 0.3423]), 0.3833)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_study = df[\n",
    "    ['study_id'] + pred_cols + CLASSES + ['img_target', 'pred_img']\n",
    "].groupby('study_id').agg(np.mean).copy()\n",
    "\n",
    "# df_study['negative_pred'] *= 1 - df_study['pred_img'] \n",
    "# df_study['typical_pred'] *= df_study['pred_img'] \n",
    "# df_study['indeterminate_pred'] *= df_study['pred_img'] \n",
    "# df_study['atypical_pred'] *= df_study['pred_img'] \n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'negative_pred'] *= 0.5\n",
    "df_study.loc[df_study['pred_img'] < 0.2, 'negative_pred'] *= 2\n",
    "\n",
    "df_study.loc[df_study['pred_img'] > 0.75, 'typical_pred'] *= 1.2\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'indeterminate_pred'] *= 1.1\n",
    "# df_study.loc[df_study['pred_img'] > 0.9, 'atypical_pred'] *= 1.1\n",
    "\n",
    "df_study.loc[df_study['pred_img'] < 0.25, 'typical_pred'] *= 0.8\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'indeterminate_pred'] *= 0.9\n",
    "# df_study.loc[df_study['pred_img'] < 0.2, 'atypical_pred'] *= 0.9\n",
    "\n",
    "accs = per_class_average_precision_score(\n",
    "    df_study[pred_cols].values,\n",
    "    df_study[CLASSES].values, \n",
    "    num_classes=NUM_CLASSES, \n",
    "    average=False\n",
    ")\n",
    "np.round(accs, 4), np.round(np.mean(accs) * 2/3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
