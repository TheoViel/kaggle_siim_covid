{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.transforms import get_transfos_lung\n",
    "from data.dataset import LungDataset\n",
    "\n",
    "from util.plot import plot_sample\n",
    "from training.main import train\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXR_PATH = \"../input/lungs/cxr_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIIM_PATH = \"../input/lungs/siim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_dic_cxr = json.load(open('../output/boxes_cxr.json', 'r'))\n",
    "boxes_dic_siim = json.load(open('../output/boxes_siim.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "    imgs = glob.glob(CXR_PATH + \"*/*.png\")\n",
    "    boxes_dic_cxr = {}\n",
    "\n",
    "    for i, img_path in tqdm(enumerate(imgs)):\n",
    "\n",
    "        base, img_name = img_path.split('/')[-2:]\n",
    "\n",
    "        mask_path = CXR_PATH + \"mask/\" + base + \"/\" + img_name\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "\n",
    "        n_components, comps, boxes, _ = cv2.connectedComponentsWithStats(mask[:, :, 0])\n",
    "\n",
    "        boxes = np.array(boxes)[1:, :-1]\n",
    "        boxes = boxes[boxes[:, 2] > 100]\n",
    "        boxes = boxes[boxes[:, 3] > 100]\n",
    "\n",
    "        if len(boxes) != 2:\n",
    "            continue\n",
    "            print(boxes)\n",
    "    #         continue\n",
    "\n",
    "        if not i % 100:\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(img)\n",
    "            plt.imshow(mask, alpha=0.2)\n",
    "\n",
    "            for box in boxes:\n",
    "        #         print(box)\n",
    "                rect = Rectangle(\n",
    "                    (box[0], box[1]), box[2], box[3],\n",
    "                    linewidth=2, edgecolor='salmon', facecolor='none'\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "            plt.axis(False)\n",
    "            plt.show()\n",
    "\n",
    "        boxes_dic_cxr[img_path] = boxes.astype(int).tolist()\n",
    "\n",
    "    with open('../output/boxes_cxr.json', 'w') as f:\n",
    "        json.dump(boxes_dic_cxr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siim-covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if GENERATE:\n",
    "\n",
    "    DATA_PATH = \"../input/\"\n",
    "    \n",
    "    df = pd.concat([\n",
    "        pd.read_csv('../input/df_train_512.csv'),\n",
    "        pd.read_csv('../input/df_test_512.csv'),\n",
    "    ])\n",
    "\n",
    "    imgs = glob.glob(SIIM_PATH + \"images/*/*.jpg\")\n",
    "    imgs_proc = glob.glob(DATA_PATH + \"train_512/*\") + glob.glob(DATA_PATH + \"test_512/*\")\n",
    "    boxes_dic_siim = {}\n",
    "\n",
    "    for i, img_path in tqdm(enumerate(imgs)):\n",
    "        base, img_name = img_path.split('/')[-2:]\n",
    "\n",
    "        img_path = [f for f in imgs_proc if img_name.split('.')[0] in f][0]\n",
    "\n",
    "        crops, orig_shape, orig_shape_crop = df[df['save_name'] == img_path.split('/')[-1]][\n",
    "            ['crop_starts', 'shape', 'shape_crop']\n",
    "        ].values[0]\n",
    "        crops = np.array(crops[1:-1].split(', ')).astype(int)\n",
    "        orig_shape = np.array(orig_shape[1:-1].split(', ')).astype(int)\n",
    "        orig_shape_crop = np.array(orig_shape_crop[1:-1].split(', ')).astype(int)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        box_path = SIIM_PATH + \"labels/\" + base + \"/\" + img_name.split('.')[0] + \".txt\"\n",
    "\n",
    "        if not os.path.exists(box_path):\n",
    "            print(box_path)\n",
    "    #         continue\n",
    "\n",
    "        boxes = open(box_path, 'r').readlines()\n",
    "        boxes = np.array([np.array(b[:-1].split(' ')).astype(float) for b in boxes])\n",
    "        boxes = boxes[boxes[:, 0] < 2][:, 1:]\n",
    "\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "    #     orig_shape_crop =  orig_shape - crops * 1.5\n",
    "\n",
    "        if crops.max():\n",
    "            boxes[:, [2, 0]] *= orig_shape[1]\n",
    "            boxes[:, [3, 1]] *= orig_shape[0]\n",
    "\n",
    "            boxes[:, 0] -= crops[1]\n",
    "            boxes[:, 1] -= crops[0]\n",
    "\n",
    "            boxes[:, [2, 0]] /= orig_shape_crop[1]\n",
    "            boxes[:, [3, 1]] /= orig_shape_crop[0]\n",
    "\n",
    "\n",
    "        if crops.max() > 300:\n",
    "            print(orig_shape, crops)\n",
    "            print(orig_shape_crop[1] / orig_shape[1], orig_shape_crop[0] / orig_shape[0])\n",
    "\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(img)\n",
    "            for box in boxes:\n",
    "\n",
    "                rect = Rectangle(\n",
    "                    ((box[0] - box[2] / 2) * w, (box[1] - box[3] / 2) * h), box[2] * w, box[3] * h,\n",
    "                    linewidth=2, edgecolor='salmon', facecolor='none'\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "            plt.axis(False)\n",
    "            plt.show()        \n",
    "\n",
    "        boxes_dic_siim[img_path] = boxes.tolist()\n",
    "\n",
    "    del boxes_dic_siim[\"../input/train_512/db5be2895a72_5cb08cd3bea3.png\"]\n",
    "    with open('../output/boxes_siim.json', 'w') as f:\n",
    "        json.dump(boxes_dic_siim, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos_lung(augment=True, bbox_format=\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LungDataset(\n",
    "    boxes_dic_cxr,\n",
    "    boxes_dic_siim,\n",
    "    bbox_format=\"yolo\",\n",
    "    transforms=transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in np.random.choice(len(dataset), 3):\n",
    "# for i in range(1):\n",
    "    i = 609\n",
    "    img, boxes, _ = dataset[i]\n",
    "    \n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plot_sample(img, boxes, bbox_format=\"yolo\", axis=True)\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"yolov5s\": 32,\n",
    "    \"efficientdet_d0\": 16,\n",
    "    \"efficientdet_d1\": 16,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    img_folder = \"../data/processed/\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "    first_epoch_eval = 3\n",
    "    verbose_plot = 1\n",
    "    \n",
    "    # k-fold\n",
    "    k = 5\n",
    "    selected_folds = [0]\n",
    "    \n",
    "    # Model\n",
    "    selected_model = \"yolov5s\"\n",
    "#     selected_model = \"efficientdet_d1\"\n",
    "    bbox_format = \"yolo\" if \"yolo\" in selected_model else \"pascal_voc\"\n",
    "    pred_format = \"pascal_voc\" #if \"yolo\" in selected_model else \"coco\"\n",
    "    num_classes = 1\n",
    "    \n",
    "    # Loss (YOLO)\n",
    "    gr = 1.0\n",
    "    autobalance = False\n",
    "    label_smoothing = 0\n",
    "    box = 0.05  # box loss gain\n",
    "    cls = 0.5  # cls loss gain\n",
    "    cls_pw = 1.0  # cls BCELoss positive_weight\n",
    "    obj = 1.0  # obj loss gain (scale with pixels)\n",
    "    obj_pw = 1.0  # obj BCELoss positive_weight\n",
    "    iou_t = 0.20  # IoU training threshold\n",
    "    anchor_t = 4.0  # anchor-multiple threshold\n",
    "    # anchors: 3  # anchors per output layer (0 to ignore)\n",
    "    fl_gamma = 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
    "    \n",
    "    # NMS\n",
    "    conf_thresh = 0.5  # 0.1\n",
    "    iou_thresh = 0.5\n",
    "\n",
    "    # Training \n",
    "    optimizer = \"Adam\"\n",
    "    momentum = 0.937\n",
    "    weight_decay = 0.0005\n",
    "    \n",
    "    batch_size = BATCH_SIZES[selected_model]\n",
    "    val_bs = batch_size\n",
    "    \n",
    "    epochs = 10\n",
    "    lr = 5e-4\n",
    "    warmup_prop = 0.1\n",
    "    \n",
    "#     mix = \"cutmix\"\n",
    "#     mix_proba = 0.5\n",
    "#     mix_alpha = 5\n",
    "    mosaic_proba = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH + \"lungs/\")\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    save_config(Config, log_folder + \"config.json\")\n",
    "    df.to_csv(log_folder + \"data.csv\", index=False)\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "meter = train(Config, boxes_dic_cxr, boxes_dic_siim, log_folder=log_folder);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
