{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to detect duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import imagehash\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_new_data, prepare_extra_data\n",
    "\n",
    "from data.dataset import CovidDataset\n",
    "from data.transforms import get_transfos\n",
    "\n",
    "# from model_zoo.models import define_model\n",
    "\n",
    "from utils.plot import plot_sample\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger, update_overall_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashes():\n",
    "    names = []\n",
    "    hashes = []\n",
    "    hashes_t = []\n",
    "\n",
    "    funcs = [\n",
    "        imagehash.average_hash,\n",
    "        imagehash.phash,\n",
    "        imagehash.dhash,\n",
    "        imagehash.whash,\n",
    "    ]\n",
    "    \n",
    "    for path in tqdm(glob.glob('../input/train_512/*.png')):\n",
    "        img_name = path.split('/')[-1]\n",
    "\n",
    "        image = Image.open(path)\n",
    "        image_t = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "        names.append(img_name)\n",
    "        hashes.append(np.array([f(image).hash for f in funcs]).reshape(-1))\n",
    "        hashes_t.append(np.array([f(image_t).hash for f in funcs]).reshape(-1))\n",
    "\n",
    "    return hashes, hashes_t, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes, hashes_t, names = get_hashes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = torch.Tensor(np.array(hashes).astype(int)).cuda()\n",
    "hashes_t = torch.Tensor(np.array(hashes_t).astype(int)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sims = [(hashes - hashes[i]).abs().mean(-1).cpu().numpy() for i in range(hashes.shape[0])] \n",
    "sims = [(hashes[i] == hashes).float().mean(-1).cpu().numpy() for i in range(hashes.shape[0])]\n",
    "sims = np.array(sims)\n",
    "sims -= np.eye(sims.shape[0])\n",
    "\n",
    "sims_t = [(hashes[i] == hashes_t).float().mean(-1).cpu().numpy() for i in range(hashes.shape[0])]\n",
    "sims_t = np.array(sims_t)\n",
    "sims_t -= np.eye(sims_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = []\n",
    "clusts = []\n",
    "transpositions = []\n",
    "for i in tqdm(range(len(names))):\n",
    "    if names[i] in found:\n",
    "        continue\n",
    "    \n",
    "    transposed = [False]\n",
    "    clust = [names[i]]\n",
    "    for j in range(len(names)):\n",
    "        if sims[i, j] > THRESHOLD:\n",
    "            found.append(names[j])\n",
    "            clust.append(names[j])\n",
    "            transposed.append(False)\n",
    "        elif sims_t[i, j] > THRESHOLD:\n",
    "            found.append(names[j])\n",
    "            clust.append(names[j])\n",
    "            transposed.append(True)\n",
    "\n",
    "    if len(clust) > 1:\n",
    "        clusts.append(clust)\n",
    "        found.append(names[i])\n",
    "        transpositions.append(transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'found {len(found)} duplicates in {len(clusts)} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../output/clusts.npy\", np.array(clusts, dtype=object))\n",
    "np.save(\"../output/found.npy\", np.array(found))\n",
    "np.save(\"../output/transpositions.npy\", np.array(transpositions, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = DATA_PATH + f\"train_{SIZE}/\"\n",
    "\n",
    "for clust, tran in zip(clusts, transpositions):\n",
    "    print(f'Clust {clust}')\n",
    "    print(f'Trans {tran}')\n",
    "    \n",
    "    plt.figure(figsize=(15, (len(clust) // 3 + 1) * 5))\n",
    "    for i, n in enumerate(clust):\n",
    "        plt.subplot(len(clust) // 3 + 1, 3, i + 1)\n",
    "        img = cv2.imread(root + n)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.boxes import *\n",
    "from data.preparation import prepare_dataframe\n",
    "from utils.plot import plot_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = np.load(\"../output/clusts.npy\", allow_pickle=True)\n",
    "found = np.load(\"../output/found.npy\")\n",
    "transpositions = np.load(\"../output/transpositions.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = handle_duplicates(df, clusts, transpositions, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
