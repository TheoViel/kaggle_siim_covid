{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import ast\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preparation import prepare_dataframe, handle_duplicates, add_additional_boxes\n",
    "from data.dataset import CovidDetDataset, CovidClsDataset\n",
    "from data.transforms import get_transfos_det, get_transfos_cls\n",
    "\n",
    "from model_zoo.models import get_model\n",
    "from model_zoo.encoders import get_encoder\n",
    "\n",
    "from utils.plot import plot_sample\n",
    "from utils.boxes import treat_boxes\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger, update_overall_logs\n",
    "\n",
    "from training.main import k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_dataframe().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusts = np.load(\"../output/clusts.npy\", allow_pickle=True)\n",
    "found = np.load(\"../output/found.npy\")\n",
    "transpositions = np.load(\"../output/transpositions.npy\", allow_pickle=True)\n",
    "\n",
    "df = handle_duplicates(df, clusts, transpositions, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_additional_boxes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(x=\"label\", hue=\"study_label\", data=df)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(x=\"study_label\", hue=\"label\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../input/df_test_512.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['shape'] = df_test['shape'].apply(lambda x: np.array(x[1:-1].split(', ')).astype(int))\n",
    "df_test['shape_crop'] = df_test['shape_crop'].apply(lambda x: np.array(x[1:-1].split(', ')).astype(int))\n",
    "df_test['crop_starts'] = df_test['crop_starts'].apply(lambda x: np.array(x[1:-1].split(', ')).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_study = pd.read_csv('../output/sub_0931_study.csv')\n",
    "pl_study[\"study_id\"] = pl_study[\"id\"].apply(lambda x: x.split('_')[0])\n",
    "pl_study.drop(['id', 'PredictionString'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_img = pd.read_csv('../output/sub_0931_img.csv')\n",
    "pl_img[\"image_id\"] = pl_img[\"id\"].apply(lambda x: x.split('_')[0])\n",
    "pl_img.drop(['id', 'PredictionString'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.merge(pl_study, how=\"left\", on=\"study_id\")\n",
    "df_test = df_test.merge(pl_img, how=\"left\", on=\"image_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_pl'] = 0\n",
    "df_test['is_pl'] = 1\n",
    "\n",
    "df['root'] = DATA_PATH + f\"train_{SIZE}/\"\n",
    "df_test['root'] = DATA_PATH + f\"test_{SIZE}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['kfold'] = -1\n",
    "df_test['img_target'] = 1 - df_test['none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[df['crop_starts'].apply(lambda x: np.max(x) > 100)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos_det(augment=True, bbox_format=\"yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = CovidDetDataset(df_, DATA_PATH + f\"train_{SIZE}/\", bbox_format=\"yolo\", transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in np.random.choice(len(dataset), 10):\n",
    "for i in range(10):\n",
    "    img, mask, y, y_img, boxes = dataset[i]\n",
    "    \n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu().numpy().transpose(1, 2, 0)\n",
    "        mask = mask.cpu().numpy()[:, :, None]\n",
    "\n",
    "    if len(boxes):\n",
    "        plt.figure(figsize=(9, 9))\n",
    "        plot_sample(img, boxes, bbox_format=\"yolo\")\n",
    "        plt.title(\n",
    "            f'{df_[\"save_name\"][i][:-4]}  -  Study target : {CLASSES[int(y)]} - '\n",
    "            f'Img target : {CLASSES_IMG[int(y_img)]}'\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "\n",
    "# class Covid_Net(nn.Module):\n",
    "#     def __init__(self,model_name,pretrained,out_features):\n",
    "#         super(Covid_Net, self).__init__()\n",
    "#         self.net = timm.create_model(model_name,pretrained=pretrained)\n",
    "        \n",
    "#         in_features = self.net.classifier.in_features\n",
    "#         self.net.global_pool = nn.Identity()\n",
    "#         self.net.classifier = nn.Identity()\n",
    "        \n",
    "#         self.logit = nn.Linear(in_features,out_features)\n",
    "        \n",
    "#     def forward(self, image):\n",
    "#         #b,c,h,w\n",
    "#         batch_size = len(image)\n",
    "#         x = self.net(image)\n",
    "#         x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "#         logit = self.logit(x)\n",
    "        \n",
    "#         return logit\n",
    "    \n",
    "# model_params = {\n",
    "#     'model_name':'tf_efficientnetv2_m_in21ft1k',\n",
    "#     'pretrained':True,\n",
    "#     'out_features':1\n",
    "# }\n",
    "\n",
    "# model = Covid_Net(**model_params)\n",
    "\n",
    "\n",
    "# torch.save(model.net.state_dict(), \"../output/pretrained_tf_efficientnetv2_m_in21ft1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_encoder('tf_efficientnet_b4_ns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('tf_efficientnetv2_m_in21ft1k', num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos_cls(augment=False)\n",
    "dataset = CovidClsDataset(df, DATA_PATH + f\"train_{SIZE}/\", transforms=transforms)\n",
    "\n",
    "x, m, y, y_img, _ = dataset[0]\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.axis(False)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(m.cpu().numpy()[:, :, None])\n",
    "plt.axis(False)\n",
    "\n",
    "x = x.unsqueeze(0).float()\n",
    "m = m.unsqueeze(0).float()\n",
    "y = y.unsqueeze(0)\n",
    "y_img = y_img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.nb_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pred:\n",
    "    try:\n",
    "        print(p.size())\n",
    "    except:\n",
    "        for p_ in p:\n",
    "            print(' ', p_.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SmoothCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss(pred[0], y), loss(pred[0], torch.tensor([[0, 1, 0, 0]]).long()), nn.CrossEntropyLoss(reduction=\"none\")(pred[0], y.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"resnext50_32x4d\": 16,\n",
    "    'tf_efficientnetv2_s_in21ft1k': 8, # 16\n",
    "    'tf_efficientnetv2_m_in21ft1k': 12, #6\n",
    "    'tf_efficientnetv2_l_in21ft1k': 6,\n",
    "    'tf_efficientnet_b2_ns': 12,\n",
    "    'tf_efficientnet_b3_ns': 16,\n",
    "    'tf_efficientnet_b4_ns': 12,\n",
    "    'tf_efficientnet_b5_ns': 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "\n",
    "    size = SIZE\n",
    "    bbox_format = \"yolo\"\n",
    "    root_dir = DATA_PATH + f\"train_{SIZE}/\"\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "\n",
    "    # k-fold\n",
    "    k = 5\n",
    "    folds_col = \"kfold\"\n",
    "    selected_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # Model\n",
    "    selected_model = 'tf_efficientnetv2_m_in21ft1k'\n",
    "    use_unet = False\n",
    "    pretrained = True\n",
    "    num_classes = len(CLASSES)\n",
    "\n",
    "    # Training\n",
    "    loss_config = {  \n",
    "        \"w_bce\": 0.75,\n",
    "        \"w_seg_loss\": 0.95 if \"v2_s\" in selected_model else 0.75,\n",
    "        \"seg_loss_multiplier\": 4 if \"v2_s\" in selected_model else 2,\n",
    "        \"w_study\": 2,\n",
    "        \"w_img\": 1,\n",
    "    }\n",
    "    use_fp16 = False if \"v2_s\" in selected_model else True\n",
    "    samples_per_patient = 1\n",
    "    optimizer = [\"Adam\", \"RAdam_lookahead\", \"RAdam\"]\n",
    "    batch_size = BATCH_SIZES[selected_model]\n",
    "    epochs = [8 if USE_PL else 10] #, 5, 5]\n",
    "\n",
    "    lr = [1e-3, 1e-4, 1e-5]\n",
    "    warmup_prop = [0.05, 0.25, 0.5]\n",
    "    val_bs = batch_size * 2\n",
    "\n",
    "    first_epoch_eval = 0\n",
    "\n",
    "    mix = \"cutmix\"\n",
    "    mix_proba = 0 if USE_PL else 0.5\n",
    "    mix_alpha = 0.4\n",
    "\n",
    "    name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    save_config(Config, log_folder + 'config')\n",
    "    df.to_csv(log_folder + 'data.csv', index=False)\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "pred_oof_study, pred_oof_img = k_fold(\n",
    "    Config,\n",
    "    df,\n",
    "    df_extra=df_test if USE_PL else None,\n",
    "    log_folder=log_folder\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
